{"cells":[{"cell_type":"markdown","metadata":{"id":"sRl3jE7Ktm6U"},"source":["# Google Drive"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34051,"status":"ok","timestamp":1739304177267,"user":{"displayName":"Will L","userId":"12700959880195069981"},"user_tz":360},"id":"4t0dzD3X8Eym","outputId":"89751869-e62a-417b-fcab-6a4c4d9a49bb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"DHt_e7S6KY_o"},"source":["# Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"vQyUyV133yy2","executionInfo":{"status":"ok","timestamp":1739304347964,"user_tz":360,"elapsed":12585,"user":{"displayName":"Will L","userId":"12700959880195069981"}}},"outputs":[],"source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision.ops import sigmoid_focal_loss\n","import torch.nn.functional as F\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader, Sampler, RandomSampler, SubsetRandomSampler, random_split\n","\n","import os\n","import random\n","import pandas as pd\n","import numpy as np\n","import pickle\n","from collections import defaultdict\n","from sklearn.metrics import matthews_corrcoef as mcc\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["# Random Seed and Batch Size"],"metadata":{"id":"w_tn_3Zt_Mb0"}},{"cell_type":"code","source":["# Set random seed and batch size for all random processes and datasets. Seed for saved datasets is 100.\n","\n","seed = 100\n","batch_size = 64"],"metadata":{"id":"dPsUV2vK1ucD","executionInfo":{"status":"ok","timestamp":1739304347965,"user_tz":360,"elapsed":7,"user":{"displayName":"Will L","userId":"12700959880195069981"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N7EtQxOLKaad"},"source":["# Save / Load Datasets"]},{"cell_type":"code","source":["languages = [('cs', 'Czech'), ('nl', 'Dutch'), ('en', 'English'), ('fr', 'French'),\n","             ('de', 'German'), ('el', 'Greek'), ('it', 'Italian'), ('ko', 'Korean'),\n","             ('no', 'Norwegian'), ('es', 'Spanish'), ('sv', 'Swedish'), ('tr', 'Turkish')]\n","\n","germanic = [('nl', 'Dutch'), ('en', 'English'), ('de', 'German')]\n","romantic = [('fr', 'French'), ('it', 'Italian'), ('es', 'Spanish')]\n","nordic = [('no', 'Norwegian'), ('sv', 'Swedish')]\n","\n","families = [('Germanic', germanic), ('Romantic', romantic), ('Nordic', nordic)]"],"metadata":{"id":"6eSldNYopVUv","executionInfo":{"status":"ok","timestamp":1739304369972,"user_tz":360,"elapsed":122,"user":{"displayName":"Will L","userId":"12700959880195069981"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Original Size Datasets"],"metadata":{"id":"eBYrx6XfpNG1"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"9YCVLoGaVh02","executionInfo":{"status":"ok","timestamp":1739304390784,"user_tz":360,"elapsed":7284,"user":{"displayName":"Will L","userId":"12700959880195069981"}}},"outputs":[],"source":["#@title Original All Lang Datasets\n","\n","data_folder = '/content/drive/MyDrive/CompLing Projects/Voynich/Final/Datasets'\n","'''\n","# Load Pickle Dataset\n","lang_folder = '/content/drive/MyDrive/CompLing Projects/Voynich/Data and scripts/New Datasets (from SunPoeppleDatabases)'\n","with open(os.path.join(lang_folder, 'Pickles', 'All_Langs.pickle'), 'rb') as f:\n","  lang_pickle = pickle.load(f)\n","\n","# Train / Val / Test split of 80/10/10\n","test_size = int(len(lang_pickle) * 0.1)\n","\n","# Stratify split using language tags.\n","lang_stratify = [entry[2] for entry in lang_pickle]\n","\n","# First split into train_pool (train + val) and test_ds.\n","train_pool, test_ds = train_test_split(lang_pickle, test_size=test_size, random_state=seed,\n","                                       shuffle=True, stratify=lang_stratify)\n","\n","# Stratify split using language tags.\n","lang_stratify = [entry[2] for entry in train_pool]\n","\n","# Then split train_pool into train_ds and val_ds\n","train_ds, val_ds = train_test_split(train_pool, test_size=test_size, random_state=seed,\n","                                    shuffle=True, stratify=lang_stratify)\n","\n","with open(os.path.join(data_folder, 'Original', 'All_Langs_Train_Original.pickle'), 'wb') as f:\n","  pickle.dump(train_ds, f)\n","with open(os.path.join(data_folder, 'Original', 'All_Langs_Val_Original.pickle'), 'wb') as f:\n","  pickle.dump(val_ds, f)\n","with open(os.path.join(data_folder, 'Original', 'All_Langs_Test_Original.pickle'), 'wb') as f:\n","  pickle.dump(test_ds, f)\n","'''\n","with open(os.path.join(data_folder, 'Original', 'All_Langs_Train_Original.pickle'), 'rb') as f:\n","  train_ds = pickle.load(f)\n","with open(os.path.join(data_folder, 'Original', 'All_Langs_Val_Original.pickle'), 'rb') as f:\n","  val_ds = pickle.load(f)\n","with open(os.path.join(data_folder, 'Original', 'All_Langs_Test_Original.pickle'), 'rb') as f:\n","  test_ds = pickle.load(f)\n","\n","train_pool = train_ds + val_ds"]},{"cell_type":"code","source":["#@title Original LOO Datasets\n","\n","# To load a dataset, use the last last lines of the commented code below with the language name filled in.\n","'''\n","for lang in languages:\n","  loo_train = [entry for entry in train_pool if entry[2] != lang[0]]\n","  lang_stratify = [entry[2] for entry in loo_train]\n","  if len(loo_train) > len(train_ds):\n","    loo_train_ds, _ = train_test_split(loo_train, train_size=len(train_ds), random_state=seed,\n","                                    shuffle=True, stratify=lang_stratify)\n","  else:\n","    loo_train_ds = shuffle(loo_train, random_state=seed)\n","\n","  loo_val_ds = [entry for entry in train_pool if entry[2] == lang[0]]\n","\n","  with open(os.path.join(data_folder, 'Original', 'LOO', f'LOO_{lang[1]}_Train_Original.pickle'), 'wb') as f:\n","    pickle.dump(loo_train_ds, f)\n","  with open(os.path.join(data_folder, 'Original', 'LOO', f'LOO_{lang[1]}_Val_Original.pickle'), 'wb') as f:\n","    pickle.dump(loo_val_ds, f)\n","'''\n","lang=languages[2]\n","# To load:\n","with open(os.path.join(data_folder, 'Original', 'LOO', f'LOO_{lang[1]}_Train_Original.pickle'), 'rb') as f:\n","  loo_train_ds = pickle.load(f)\n","with open(os.path.join(data_folder, 'Original', 'LOO', f'LOO_{lang[1]}_Val_Original.pickle'), 'rb') as f:\n","  loo_val_ds = pickle.load(f)\n","\n","print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2rTnos5M5uZO","executionInfo":{"status":"ok","timestamp":1739304493532,"user_tz":360,"elapsed":4205,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"1f8e053b-c054-4dad-ff7b-7fef390ebd26"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","source":["for lang in languages:\n","  # Set random seeds\n","  random.seed(seed)\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","\n","  # Set Datasets\n","  with open(os.path.join(data_folder, 'Original', 'LOO', f'LOO_{lang[1]}_Train_Original.pickle'), 'rb') as f:\n","    loo_train_ds = pickle.load(f)\n","  with open(os.path.join(data_folder, 'Original', 'LOO', f'LOO_{lang[1]}_Val_Original.pickle'), 'rb') as f:\n","    loo_val_ds = pickle.load(f)\n","  print(lang)\n","  print('Train:', set([entry[2] for entry in loo_train_ds]))\n","  print('Val:', set([entry[2] for entry in loo_val_ds]))\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iT1y00jNKAwM","executionInfo":{"status":"ok","timestamp":1739304564251,"user_tz":360,"elapsed":58052,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"95704bc1-e23e-4c4e-872a-8d302f602fe8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["('cs', 'Czech')\n","Train: {'el', 'tr', 'es', 'ko', 'fr', 'no', 'it', 'nl', 'de', 'en', 'sv'}\n","Val: {'cs'}\n","\n","('nl', 'Dutch')\n","Train: {'el', 'es', 'tr', 'ko', 'fr', 'cs', 'no', 'it', 'de', 'en', 'sv'}\n","Val: {'nl'}\n","\n","('en', 'English')\n","Train: {'es', 'el', 'tr', 'ko', 'fr', 'cs', 'no', 'it', 'nl', 'de', 'sv'}\n","Val: {'en'}\n","\n","('fr', 'French')\n","Train: {'el', 'es', 'tr', 'ko', 'cs', 'no', 'it', 'nl', 'de', 'en', 'sv'}\n","Val: {'fr'}\n","\n","('de', 'German')\n","Train: {'el', 'es', 'ko', 'fr', 'cs', 'no', 'it', 'nl', 'tr', 'en', 'sv'}\n","Val: {'de'}\n","\n","('el', 'Greek')\n","Train: {'es', 'tr', 'ko', 'fr', 'cs', 'no', 'it', 'nl', 'de', 'en', 'sv'}\n","Val: {'el'}\n","\n","('it', 'Italian')\n","Train: {'es', 'tr', 'el', 'ko', 'fr', 'cs', 'no', 'nl', 'de', 'en', 'sv'}\n","Val: {'it'}\n","\n","('ko', 'Korean')\n","Train: {'el', 'tr', 'es', 'fr', 'cs', 'no', 'it', 'nl', 'de', 'en', 'sv'}\n","Val: {'ko'}\n","\n","('no', 'Norwegian')\n","Train: {'el', 'es', 'ko', 'fr', 'cs', 'de', 'it', 'nl', 'tr', 'en', 'sv'}\n","Val: {'no'}\n","\n","('es', 'Spanish')\n","Train: {'el', 'tr', 'ko', 'fr', 'cs', 'no', 'it', 'nl', 'de', 'en', 'sv'}\n","Val: {'es'}\n","\n","('sv', 'Swedish')\n","Train: {'es', 'el', 'ko', 'fr', 'cs', 'no', 'it', 'nl', 'de', 'en', 'tr'}\n","Val: {'sv'}\n","\n","('tr', 'Turkish')\n","Train: {'el', 'es', 'ko', 'fr', 'cs', 'no', 'it', 'nl', 'de', 'en', 'sv'}\n","Val: {'tr'}\n","\n"]}]},{"cell_type":"code","source":["with open(os.path.join(data_folder, 'Original', 'LOO', f'LOO_Dutch_Train_Original.pickle'), 'rb') as f:\n","  loo_train_ds = pickle.load(f)\n","with open(os.path.join(data_folder, 'Original', 'LOO', f'LOO_Dutch_Val_Original.pickle'), 'rb') as f:\n","  loo_val_ds = pickle.load(f)"],"metadata":{"id":"t2Qt8aGRSz-m","executionInfo":{"status":"ok","timestamp":1739304588486,"user_tz":360,"elapsed":3260,"user":{"displayName":"Will L","userId":"12700959880195069981"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["loo_train_ds[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cEKrTz_0S4Vk","executionInfo":{"status":"ok","timestamp":1739304590788,"user_tz":360,"elapsed":144,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"5e3aaba6-afab-4f9c-9538-42f16f201752"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(array([3.68616148, 2.13868702, 1.87839558, 1.99691402, 3.169925  ,\n","         0.        , 0.53051472, 0.        , 0.        , 0.        ,\n","         2.169925  , 1.        , 0.        , 0.        , 0.        ]),\n","  array([1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0]),\n","  'sv',\n","  'f9ZT2relsevApen'),\n"," (array([2.67677992, 3.67203057, 0.36881448, 2.95311361, 3.42626475,\n","         2.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        ]),\n","  array([1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0]),\n","  'el',\n","  'adikleptikos'),\n"," (array([4.65988009, 3.14577114, 1.87005383, 5.30985526, 0.5849625 ,\n","         0.        , 1.        ]),\n","  array([1, 0, 0, 1, 0, 0, 0]),\n","  'sv',\n","  'vAlvInd'),\n"," (array([6.41576115, 3.30875271, 1.1793237 , 0.13326653, 2.95419631,\n","         1.        , 1.        , 0.        ]),\n","  array([1, 0, 0, 0, 1, 0, 1, 0]),\n","  'no',\n","  'C9nsb6IN'),\n"," (array([3.86169538, 4.58271055, 2.84645474, 2.11547722, 1.        ,\n","         0.        , 0.5849625 , 1.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ]),\n","  array([1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0]),\n","  'no',\n","  'bistAnsmInIst@r'),\n"," (array([4.37638158, 3.93204639, 1.23972703, 0.97797369, 0.        ,\n","         0.0671142 , 0.02308361, 3.95419631, 0.4150375 , 1.5849625 ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        ]),\n","  array([1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]),\n","  'sv',\n","  'peZUnAl}tbIldnIN'),\n"," (array([3.52283588, 2.44558529, 3.61560177, 1.13750352, 4.9068906 ,\n","         0.        , 0.        , 0.        , 0.        ]),\n","  array([1, 0, 0, 0, 1, 0, 1, 0, 0]),\n","  'de',\n","  'SpErg@bit'),\n"," (array([5.67501886, 2.33328796, 4.39803107, 1.        , 0.26303441,\n","         2.32192809, 0.        , 0.        , 0.        , 0.        ,\n","         0.        ]),\n","  array([1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0]),\n","  'no',\n","  'Eldr@sEnt@r'),\n"," (array([4.09984804, 0.71545413, 4.85030707, 4.11547722, 0.5849625 ,\n","         1.        , 0.        , 0.        , 0.        ]),\n","  array([1, 0, 1, 0, 0, 1, 0, 1, 0]),\n","  'it',\n","  'inGlobare'),\n"," (array([9.34170413, 4.22881869, 0.4150375 , 0.        , 1.        ,\n","         0.        , 0.        , 0.5849625 , 0.        , 0.        ,\n","         1.        ]),\n","  array([1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0]),\n","  'sv',\n","  '6stralI4nsk'),\n"," (array([5.44415836, 2.33091688, 6.32192809, 1.        , 0.        ,\n","         0.        , 0.        , 0.        ]),\n","  array([1, 0, 1, 0, 0, 1, 0, 0]),\n","  'el',\n","  'letraset'),\n"," (array([3.40894691, 2.95710204, 2.73321346, 2.56634682]),\n","  array([1, 0, 1, 0]),\n","  'it',\n","  'alto'),\n"," (array([4.90503695, 3.05667245, 2.03747471, 0.34103692, 3.9068906 ,\n","         1.        , 0.        ]),\n","  array([1, 0, 0, 0, 1, 0, 0]),\n","  'en',\n","  'l{ndm#k'),\n"," (array([4.09300355, 4.44270992, 3.82781902, 1.32192809, 1.        ,\n","         0.        ]),\n","  array([1, 0, 1, 0, 1, 0]),\n","  'es',\n","  'rITAdO'),\n"," (array([4.14777186, 5.04911267, 2.79441587, 3.        , 0.        ,\n","         1.        , 0.        ]),\n","  array([1, 0, 0, 1, 1, 0, 0]),\n","  'no',\n","  'tveEg@t'),\n"," (array([3.03439705, 6.08491466, 5.12928302, 2.32192809]),\n","  array([1, 0, 1, 0]),\n","  'sv',\n","  's0sa'),\n"," (array([4.26591754, 3.68949886, 4.3479233 , 1.87446912, 1.5849625 ,\n","         0.        , 0.        ]),\n","  array([1, 0, 0, 1, 0, 1, 0]),\n","  'ko',\n","  'codrlek'),\n"," (array([3.97163198, 2.51025588, 7.38658105, 0.5849625 , 0.        ,\n","         1.        ]),\n","  array([1, 0, 0, 1, 0, 0]),\n","  'cs',\n","  'ka7kaT'),\n"," (array([3.25719783, 1.41623562, 2.55306415, 2.35819164, 1.13750352,\n","         1.64385619, 0.        , 0.        , 0.67807191, 0.73696559,\n","         0.5849625 , 0.        , 0.        , 1.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        ]),\n","  array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]),\n","  'it',\n","  'kommercaliZZazzjone'),\n"," (array([3.47397241, 3.26138655, 3.05232104, 1.13750352, 4.32192809,\n","         0.        , 0.        ]),\n","  array([1, 0, 0, 1, 0, 0, 0]),\n","  'en',\n","  'k{mpj@n')]"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["loo_val_ds[:20]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XmaMb_GNTDRQ","executionInfo":{"status":"ok","timestamp":1739304618397,"user_tz":360,"elapsed":304,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"52d8abd8-71f9-42cb-84ea-1411cccd2410"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(array([3.83713252, 3.59892389, 1.91919625, 7.48381578, 0.        ]),\n","  array([1, 0, 0, 1, 0]),\n","  'nl',\n","  'vrKAf'),\n"," (array([5.17417676, 3.86399177, 3.10046018, 1.37851162, 0.73696559,\n","         1.5849625 , 1.        ]),\n","  array([1, 0, 1, 0, 1, 0, 0]),\n","  'nl',\n","  'zal@G@r'),\n"," (array([4.65915934, 3.53245066, 2.60306431, 0.87446912, 0.        ,\n","         0.46948528, 0.        , 0.05658353, 0.        , 4.64385619,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        ]),\n","  array([1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]),\n","  'nl',\n","  'lit@ratyrkritik}s'),\n"," (array([3.70737221, 1.79073346, 3.04634202, 1.63640927, 0.26589406,\n","         0.03476542, 3.7725895 , 1.5849625 , 0.        , 1.        ,\n","         0.        , 0.        , 0.        , 0.        ]),\n","  array([1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]),\n","  'nl',\n","  'b@lKtskOnflIkt'),\n"," (array([3.83713252, 4.28083672, 3.67670507, 2.45943162, 0.5849625 ]),\n","  array([1, 0, 0, 0, 0]),\n","  'nl',\n","  'vANst'),\n"," (array([4.49504999, 4.65053148, 4.69348696, 3.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ]),\n","  array([1, 0, 1, 0, 0, 1, 0, 1, 0, 0]),\n","  'nl',\n","  't@latkom@r'),\n"," (array([3.70737221, 4.676369  , 1.19793938, 2.12810483, 1.6698514 ,\n","         1.87446912, 0.5849625 , 0.        ]),\n","  array([1, 0, 0, 0, 1, 0, 0, 0]),\n","  'nl',\n","  'bErxspor'),\n"," (array([3.97739991, 4.25433821, 0.70043972, 0.81942775, 4.76553475,\n","         0.        , 0.        , 0.        , 2.32192809, 0.        ,\n","         0.        ]),\n","  array([1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0]),\n","  'nl',\n","  'polixromer@'),\n"," (array([3.24008546, 1.88302098, 3.14990795, 1.83813358, 3.02748074,\n","         0.70043972, 0.19264508, 1.22239242, 1.5849625 , 0.        ]),\n","  array([1, 0, 0, 0, 1, 0, 1, 0, 0, 0]),\n","  'nl',\n","  'stAthLstKl'),\n"," (array([4.69600415, 2.2271849 , 1.67747464, 3.48351724, 2.43295941,\n","         2.32192809, 0.        , 0.        ]),\n","  array([1, 0, 0, 0, 1, 0, 0, 0]),\n","  'nl',\n","  'wErptrOs'),\n"," (array([5.17417676, 2.71652444, 2.79862011, 3.3423922 ]),\n","  array([1, 0, 0, 0]),\n","  'nl',\n","  'zwep'),\n"," (array([4.50144653, 4.41875866, 1.87446912, 2.87446912, 3.169925  ,\n","         0.        ]),\n","  array([1, 0, 0, 1, 0, 0]),\n","  'nl',\n","  'hukpal'),\n"," (array([3.24008546, 1.88302098, 3.27717014, 2.41642404, 4.43740531,\n","         0.5849625 , 1.        , 0.        ]),\n","  array([1, 0, 0, 0, 1, 0, 0, 0]),\n","  'nl',\n","  'stekflix'),\n"," (array([4.65915934, 3.55420025, 2.76772785, 5.857981  , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        ]),\n","  array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]),\n","  'nl',\n","  'lonov@rtredIN'),\n"," (array([8.63449729, 3.88264305, 2.        , 0.        , 0.        ,\n","         0.32192809, 2.        , 0.        , 0.        ]),\n","  array([1, 0, 1, 0, 0, 1, 0, 1, 0]),\n","  'nl',\n","  'Sabloner@'),\n"," (array([3.70737221, 1.79073346, 4.01903467, 4.73696559, 1.5849625 ,\n","         1.        , 0.        ]),\n","  array([1, 0, 1, 0, 1, 0, 0]),\n","  'nl',\n","  'b@rovIN'),\n"," (array([3.70737221, 1.79073346, 3.94008333, 1.07895134, 1.79836614,\n","         0.27563444, 0.07800251, 0.        , 0.        , 0.169925  ,\n","         3.        , 1.        , 0.        , 0.        , 0.        ,\n","         0.        , 0.        , 0.        , 0.        , 0.        ]),\n","  array([1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0]),\n","  'nl',\n","  'b@Graf@nIsplExt@xhKt'),\n"," (array([4.49089356, 3.82069786, 1.78601002, 1.06904164, 3.08746284,\n","         2.5849625 , 0.        , 0.        , 0.        , 0.        ]),\n","  array([1, 0, 0, 0, 1, 0, 0, 0, 1, 0]),\n","  'nl',\n","  'rAntf}Nksi'),\n"," (array([4.50144653, 3.66519656, 2.01421386, 0.33628339, 0.13210354,\n","         2.01989956, 1.36257008, 2.80735492, 0.        ]),\n","  array([1, 0, 0, 1, 0, 0, 0, 1, 0]),\n","  'nl',\n","  'hOnd@rtj@'),\n"," (array([4.49504999, 4.86828501, 1.77529371, 2.        , 2.11547722,\n","         0.        , 0.        , 0.        , 0.        ]),\n","  array([1, 0, 0, 1, 0, 1, 0, 0, 0]),\n","  'nl',\n","  'tindLz@nt')]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["#@title Original Family Datasets\n","\n","# To load a dataset, use the last last lines of the commented code below with the language name filled in.\n","'''\n","for family in families:\n","  for lang in family[1]:\n","    train_langs = set([entry[0] for entry in family[1] if entry != lang])\n","    family_train_ds = shuffle([entry for entry in train_pool if entry[2] in train_langs], random_state=seed)\n","    family_val_ds = shuffle([entry for entry in train_pool if entry[2] == lang[0]], random_state=seed)\n","    with open(os.path.join(data_folder, 'Original', 'Family', f'{family[0]}_{lang[1]}_Train_Original.pickle'), 'wb') as f:\n","      pickle.dump(family_train_ds, f)\n","    with open(os.path.join(data_folder, 'Original', 'Family', f'{family[0]}_{lang[1]}_Val_Original.pickle'), 'wb') as f:\n","      pickle.dump(family_val_ds, f)\n","\n","# To load:\n","with open(os.path.join(data_folder, 'Original', 'Family', f'{family[0]}_{lang[1]}_Train_Original.pickle'), 'rb') as f:\n","  family_train_ds = pickle.load(f)\n","with open(os.path.join(data_folder, 'Original', 'Family', f'{family[0]}_{lang[1]}_Val_Original.pickle'), 'rb') as f:\n","  family_val_ds = pickle.load(f)\n","'''\n","print()"],"metadata":{"id":"f3GttKZnQlVa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713023478231,"user_tz":300,"elapsed":178,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"3bb89d49-f814-4d30-e890-b10b15210bdd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"markdown","source":["## Uniform Size Datasets"],"metadata":{"id":"UvbGT8t5Qf4X"}},{"cell_type":"code","source":["#@title Uniform All Lang Datasets\n","data_folder = '/content/drive/MyDrive/CompLing Projects/Voynich/Final/Datasets'\n","'''\n","uniform_train = []\n","uniform_val = []\n","uniform_test = []\n","\n","for lang in languages:\n","  uniform_train += shuffle([entry for entry in train_ds if entry[2]==lang[0]], random_state=seed, n_samples=12000)\n","  uniform_val += shuffle([entry for entry in val_ds if entry[2]==lang[0]], random_state=seed, n_samples=1500)\n","  uniform_test += shuffle([entry for entry in test_ds if entry[2]==lang[0]], random_state=seed, n_samples=1500)\n","\n","uniform_train_ds = shuffle(uniform_train, random_state=seed)\n","uniform_val_ds = shuffle(uniform_val)\n","uniform_test_ds = shuffle(uniform_test)\n","\n","with open(os.path.join(data_folder, 'Uniform', 'All_Langs_Train_Uniform.pickle'), 'wb') as f:\n","  pickle.dump(uniform_train_ds, f)\n","with open(os.path.join(data_folder, 'Uniform', 'All_Langs_Val_Uniform.pickle'), 'wb') as f:\n","  pickle.dump(uniform_val_ds, f)\n","with open(os.path.join(data_folder, 'Uniform', 'All_Langs_Test_Uniform.pickle'), 'wb') as f:\n","  pickle.dump(uniform_test_ds, f)\n","'''\n","with open(os.path.join(data_folder, 'Uniform', 'All_Langs_Train_Uniform.pickle'), 'rb') as f:\n","  uniform_train_ds = pickle.load(f)\n","with open(os.path.join(data_folder, 'Uniform', 'All_Langs_Val_Uniform.pickle'), 'rb') as f:\n","  uniform_val_ds = pickle.load(f)\n","with open(os.path.join(data_folder, 'Uniform', 'All_Langs_Test_Uniform.pickle'), 'rb') as f:\n","  uniform_test_ds = pickle.load(f)\n","\n","uniform_train_pool = uniform_train_ds + uniform_val_ds"],"metadata":{"id":"By3EJspAQeck"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Uniform LOO Datasets\n","\n","# To load a dataset, use the last last lines of the commented code below with the language name filled in.\n","'''\n","for lang in languages:\n","  loo_train = [entry for entry in uniform_train_pool if entry[2] != lang[0]]\n","  lang_stratify = [entry[2] for entry in loo_train]\n","  loo_train_ds, _ = train_test_split(loo_train, train_size=144001, random_state=seed,\n","                                     shuffle=True, stratify=lang_stratify)\n","  loo_val_ds = [entry for entry in uniform_train_pool if entry[2] == lang[0]]\n","\n","  with open(os.path.join(data_folder, 'Uniform', 'LOO', f'LOO_{lang[1]}_Train_Uniform.pickle'), 'wb') as f:\n","    pickle.dump(loo_train_ds, f)\n","  with open(os.path.join(data_folder, 'Uniform', 'LOO', f'LOO_{lang[1]}_Val_Uniform.pickle'), 'wb') as f:\n","    pickle.dump(loo_val_ds, f)\n","\n","# To load:\n","with open(os.path.join(data_folder, 'Uniform', 'LOO', f'LOO_{lang[1]}_Train_Uniform.pickle'), 'rb') as f:\n","  loo_train_ds = pickle.load(f)\n","with open(os.path.join(data_folder, 'Uniform', 'LOO', f'LOO_{lang[1]}_Val_Uniform.pickle'), 'rb') as f:\n","  loo_val_ds = pickle.load(f)\n","'''\n","print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGOt7JwtTODK","executionInfo":{"status":"ok","timestamp":1713023490976,"user_tz":300,"elapsed":170,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"112867c6-d07e-4923-aab7-9635b478984a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","source":["#@title Uniform Family Datasets\n","\n","# To load a dataset, use the last last lines of the commented code below with the language name filled in.\n","'''\n","for family in families:\n","  for lang in family[1]:\n","    train_langs = set([entry[0] for entry in family[1] if entry != lang])\n","    family_train_ds = shuffle([entry for entry in uniform_train_pool if entry[2] in train_langs], random_state=seed)\n","    family_val_ds = shuffle([entry for entry in uniform_train_pool if entry[2] == lang[0]], random_state=seed)\n","    with open(os.path.join(data_folder, 'Uniform', 'Family', f'{family[0]}_{lang[1]}_Train_Uniform.pickle'), 'wb') as f:\n","      pickle.dump(family_train_ds, f)\n","    with open(os.path.join(data_folder, 'Uniform', 'Family', f'{family[0]}_{lang[1]}_Val_Uniform.pickle'), 'wb') as f:\n","      pickle.dump(family_val_ds, f)\n","\n","# To load:\n","with open(os.path.join(data_folder, 'Uniform', 'Family', f'{family[0]}_{lang[1]}_Train_Uniform.pickle'), 'rb') as f:\n","  family_train_ds = pickle.load(f)\n","with open(os.path.join(data_folder, 'Uniform', 'Family', f'{family[0]}_{lang[1]}_Val_Uniform.pickle'), 'rb') as f:\n","  family_val_ds = pickle.load(f)\n","'''\n","print()"],"metadata":{"id":"Hebr7m6-YwvA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713070712953,"user_tz":300,"elapsed":7914,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"c11bcc84-5960-4650-e668-ccdd7b5c2cff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"markdown","source":["# Load and Check Datasets"],"metadata":{"id":"CV3BkcEFKRPn"}},{"cell_type":"markdown","source":["## Original Size Datasets"],"metadata":{"id":"WCSEVFacNFX7"}},{"cell_type":"code","source":["#@title Number of Segments and Syllables in All Lang Datasets\n","lang_folder = '/content/drive/MyDrive/CompLing Projects/Voynich/Data and scripts/New Datasets (from SunPoeppleDatabases)'\n","\n","lang_df = pd.read_csv(os.path.join(lang_folder, 'All_Langs.csv'), index_col=0)\n","\n","num_segments = []\n","num_syllables = []\n","\n","# Train Set\n","num_segments.append(sum([len(train_ds[i][0]) for i in range(len(train_ds))]))\n","num_syllables.append(sum([train_ds[i][1].sum() for i in range(len(train_ds))]))\n","\n","# Val Set\n","num_segments.append(sum([len(val_ds[i][0]) for i in range(len(val_ds))]))\n","num_syllables.append(sum([val_ds[i][1].sum() for i in range(len(val_ds))]))\n","\n","# Test Set\n","num_segments.append(sum([len(test_ds[i][0]) for i in range(len(test_ds))]))\n","num_syllables.append(sum([test_ds[i][1].sum() for i in range(len(test_ds))]))\n","\n","# Overall\n","num_segments.append(len(lang_df))\n","num_syllables.append(lang_df['syllable'].sum())\n","\n","# W/out Head, i.e. without the first position (which is always a syllable break)\n","num_segments.append(len(lang_df) - lang_df['word_id'].max())\n","num_syllables.append(lang_df['syllable'].sum() - lang_df['word_id'].max())\n","\n","datasets = ['Train', 'Val', 'Test', 'Overall', 'W/out Head']\n","\n","count_df = pd.DataFrame(data = {'Dataset':datasets,\n","                                'Num Segments':num_segments,\n","                                'Num Syllables':num_syllables})\n","count_df['% Syllables'] = count_df['Num Syllables'] / count_df['Num Segments']\n","'''\n","count_df.to_csv(os.path.join(lang_folder, 'Stats', 'All_Languages.csv'), index=False)\n","\n","count_df = pd.read_csv(os.path.join(lang_folder, 'Stats', 'All_Languages.csv'))\n","'''\n","# Check that Train + Val + Test Segments and Syllables add up to Overall Segments and Syllables\n","assert count_df.iloc[:3]['Num Segments'].sum() == count_df.loc[3,'Num Segments']\n","assert count_df.iloc[:3]['Num Syllables'].sum() == count_df.loc[3,'Num Syllables']\n","\n","pd.options.display.precision = 2\n","count_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"pb8XZkYNKUFg","executionInfo":{"status":"ok","timestamp":1713023974941,"user_tz":300,"elapsed":8664,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"ab5d94ee-5346-453f-dfc7-c3a258baa9ea"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      Dataset  Num Segments  Num Syllables  % Syllables\n","0       Train       4215314        1655769         0.39\n","1         Val        527295         207086         0.39\n","2        Test        528941         207872         0.39\n","3     Overall       5271550        2070727         0.39\n","4  W/out Head       4642808        1441985         0.31"],"text/html":["\n","  <div id=\"df-c9c29091-8a23-4d20-807f-daa332fed638\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataset</th>\n","      <th>Num Segments</th>\n","      <th>Num Syllables</th>\n","      <th>% Syllables</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Train</td>\n","      <td>4215314</td>\n","      <td>1655769</td>\n","      <td>0.39</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Val</td>\n","      <td>527295</td>\n","      <td>207086</td>\n","      <td>0.39</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Test</td>\n","      <td>528941</td>\n","      <td>207872</td>\n","      <td>0.39</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Overall</td>\n","      <td>5271550</td>\n","      <td>2070727</td>\n","      <td>0.39</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>W/out Head</td>\n","      <td>4642808</td>\n","      <td>1441985</td>\n","      <td>0.31</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9c29091-8a23-4d20-807f-daa332fed638')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c9c29091-8a23-4d20-807f-daa332fed638 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c9c29091-8a23-4d20-807f-daa332fed638');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-2e224e51-8492-4f8c-a9be-5bacf4810e3f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2e224e51-8492-4f8c-a9be-5bacf4810e3f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-2e224e51-8492-4f8c-a9be-5bacf4810e3f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_4bc14ea2-e050-44ca-897f-30ce7e0ddf76\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('count_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_4bc14ea2-e050-44ca-897f-30ce7e0ddf76 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('count_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"count_df","summary":"{\n  \"name\": \"count_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Val\",\n          \"W/out Head\",\n          \"Test\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Num Segments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2321057,\n        \"min\": 527295,\n        \"max\": 5271550,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          527295,\n          4642808,\n          528941\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Num Syllables\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 860223,\n        \"min\": 207086,\n        \"max\": 2070727,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          207086,\n          1441985,\n          207872\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"% Syllables\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03678354866740352,\n        \"min\": 0.3105846720346825,\n        \"max\": 0.3929965723965433,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3927327207730018,\n          0.3105846720346825,\n          0.3929965723965433\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["## Uniform Size Datasets"],"metadata":{"id":"U-46-skNNulY"}},{"cell_type":"code","source":["#@title Number of Segments and Syllables in All Lang Datasets\n","\n","num_segments = []\n","num_syllables = []\n","\n","# Train Set\n","num_segments.append(sum([len(uniform_train_ds[i][0]) for i in range(len(uniform_train_ds))]))\n","num_syllables.append(sum([uniform_train_ds[i][1].sum() for i in range(len(uniform_train_ds))]))\n","\n","# Val Set\n","num_segments.append(sum([len(uniform_val_ds[i][0]) for i in range(len(uniform_val_ds))]))\n","num_syllables.append(sum([uniform_val_ds[i][1].sum() for i in range(len(uniform_val_ds))]))\n","\n","# Test Set\n","num_segments.append(sum([len(uniform_test_ds[i][0]) for i in range(len(uniform_test_ds))]))\n","num_syllables.append(sum([uniform_test_ds[i][1].sum() for i in range(len(uniform_test_ds))]))\n","\n","# Overall\n","num_segments.append(sum(num_segments))\n","num_syllables.append(sum(num_syllables))\n","\n","datasets = ['Train', 'Val', 'Test', 'Overall']\n","\n","count_df = pd.DataFrame(data = {'Dataset':datasets,\n","                                'Num Segments':num_segments,\n","                                'Num Syllables':num_syllables})\n","count_df['% Syllables'] = count_df['Num Syllables'] / count_df['Num Segments']\n","'''\n","count_df.to_csv(os.path.join(lang_folder, 'Stats', 'All_Languages.csv'), index=False)\n","\n","count_df = pd.read_csv(os.path.join(lang_folder, 'Stats', 'All_Languages.csv'))\n","'''\n","# Check that Train + Val + Test Segments and Syllables add up to Overall Segments and Syllables\n","assert count_df.iloc[:3]['Num Segments'].sum() == count_df.loc[3,'Num Segments']\n","assert count_df.iloc[:3]['Num Syllables'].sum() == count_df.loc[3,'Num Syllables']\n","\n","pd.options.display.precision = 2\n","count_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"UlvYUgqVMJdi","executionInfo":{"status":"ok","timestamp":1713024504509,"user_tz":300,"elapsed":1138,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"0d16e053-09bc-4e53-a159-2cd1c0b54545"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Dataset  Num Segments  Num Syllables  % Syllables\n","0    Train       1159651         468765          0.4\n","1      Val        144906          58490          0.4\n","2     Test        145195          58688          0.4\n","3  Overall       1449752         585943          0.4"],"text/html":["\n","  <div id=\"df-f7ae1445-2d73-4c1e-bb93-af8c8f457716\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataset</th>\n","      <th>Num Segments</th>\n","      <th>Num Syllables</th>\n","      <th>% Syllables</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Train</td>\n","      <td>1159651</td>\n","      <td>468765</td>\n","      <td>0.4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Val</td>\n","      <td>144906</td>\n","      <td>58490</td>\n","      <td>0.4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Test</td>\n","      <td>145195</td>\n","      <td>58688</td>\n","      <td>0.4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Overall</td>\n","      <td>1449752</td>\n","      <td>585943</td>\n","      <td>0.4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7ae1445-2d73-4c1e-bb93-af8c8f457716')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f7ae1445-2d73-4c1e-bb93-af8c8f457716 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f7ae1445-2d73-4c1e-bb93-af8c8f457716');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-fe7dfe3f-bc4b-407f-b236-e5b3bbe610fe\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe7dfe3f-bc4b-407f-b236-e5b3bbe610fe')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-fe7dfe3f-bc4b-407f-b236-e5b3bbe610fe button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_f16d90b4-5ef8-4707-8d47-bb6cc1f6fde5\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('count_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_f16d90b4-5ef8-4707-8d47-bb6cc1f6fde5 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('count_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"count_df","summary":"{\n  \"name\": \"count_df\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Val\",\n          \"Overall\",\n          \"Train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Num Segments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 679919,\n        \"min\": 144906,\n        \"max\": 1449752,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          144906,\n          1449752,\n          1159651\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Num Syllables\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 274836,\n        \"min\": 58490,\n        \"max\": 585943,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          58490,\n          585943,\n          468765\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"% Syllables\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0002803718115388939,\n        \"min\": 0.403640981049784,\n        \"max\": 0.4042293759070617,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.403640981049784,\n          0.40416774731126426,\n          0.4042293759070617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# Batch Sampler\n","\n","The EqualLengthsBatchSampler groups samples into batches based on sample-length, e.g. all 8-letter words appear only with other 8-letter words. This eliminates the need for padding.\n","\n","It also makes the batch sizes as close to equal as possible while not overstepping the specified `batch_size`. For example, if `batch_size` is 64 and there are 65 samples, rather than create batches of size [64, 1], it will create batches of size [33, 32]. This also means that, as long as there are more samples than the specified `batch_size`, the smallest batch will always be at least `batch_size // 2`.\n","\n","Based on this, I have decided to delete any sample lengths that have fewer than `batch_size // 2` samples. This is because some sample-lengths have very few or even just one sample in the dataset. If these small groups of samples are passed along as their own batches, they will be given equal weight to groups of samples up to the full `batch_size`, e.g. a single sample of length 31 would be given the same weight as 64 samples of length 8, assuming `batch_size = 64`.\n","\n","This results in the loss of the longest samples in our dataset, which could introduce some bias into our model (e.g. making it worse at predicting syllable breaks for long words), but the overall number of samples lost is not significant. You can see the lengths and numbers of samples dropped using the method `show_dropped_samples()`, and you can return a dictionary of the dropped samples themselves using the method `dropped_samples()`. Conversely, you can show the lengths and numbers of samples retained in the dataset after equal length batch sampling using the method `show_batches()`.\n","\n","**Note:** To get deterministic behavior from the EqualLengthsBatchSampler, you need to initialize it with a seed each time you initialize the corresponding DataLoader. If you initialize a new DataLoader without re-initializing the Sampler, it will not reset the RNG within the sampler and so you will get new samples for the new DataLoader. Example code is show below:\n","\n","```\n","train_sampler = EqualLengthsBatchSampler(train_ds, batch_size, seed)\n","train_dl = DataLoader(train_ds, batch_sampler=train_sampler)\n","fnn_model = NgramFNN(n_gram=7, d_hidden=15, n_layers=5).to(device)\n","fnn_model.fit_wandb(train_dl, val_dl, epochs=10, loss_fn='bce')\n","```\n","Each of the 10 epochs will give uniquely shuffled batches, but if you run the code block again it will give you the same 10 batches as the first time you ran it. If you don't want this behavior, feed in `seed=None`."],"metadata":{"id":"TwmqRqGajWKy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6E26kPO__u_"},"outputs":[],"source":["# Code copied (with edits and additional functions) from\n","# https://discuss.pytorch.org/t/tensorflow-esque-bucket-by-sequence-length/41284/27\n","\n","class EqualLengthsBatchSampler(Sampler):\n","\n","    def __init__(self, dataset, batch_size, seed):\n","\n","        # Set random seed\n","        self.rng = np.random.default_rng(seed)\n","\n","        # Remember batch size and number of samples\n","        self.batch_size = batch_size\n","\n","        self.unique_lengths = set()\n","        self.samples = defaultdict(list)\n","\n","        for i in range(0, len(dataset)):\n","            len_input = len(dataset[i][0])\n","\n","            # Add length to set of all seen lengths\n","            self.unique_lengths.add(len_input)\n","\n","            # For each length, keep track of which sample indices for this length\n","            # E.g.: self.lengths_to_sample = { 4: [3,5,11], 5: [1,2,9], ...}\n","            self.samples[len_input].append(i)\n","\n","        # Delete lengths and corresponding samples if there are fewer than batch_size // 2\n","        # samples of that length.\n","        self.small_samples = set()\n","        for length in self.unique_lengths:\n","            if len(self.samples[length]) < batch_size // 2:\n","                self.small_samples.add(length)\n","\n","        self.unique_lengths = self.unique_lengths - self.small_samples\n","\n","        # Convert set of unique lengths to a list so we can shuffle it later\n","        self.unique_lengths = list(self.unique_lengths)\n","\n","    def __len__(self):\n","        batches = 0\n","        for length in self.unique_lengths:\n","          batches += np.ceil(len(self.samples[length]) / self.batch_size).astype(int)\n","        return batches\n","\n","    def __iter__(self):\n","\n","        # Make list to store all batches of any length\n","        all_batches = []\n","\n","        # Shuffle list of unique length pairs\n","        self.rng.shuffle(self.unique_lengths)\n","\n","        # Iterate over all possible word lengths\n","        for length in self.unique_lengths:\n","\n","            # Get indices of all samples for the current lengths\n","            # for example, all indices with a length of 8\n","            sequence_indices = self.samples[length]\n","            sequence_indices = np.array(sequence_indices)\n","\n","            # Shuffle array of sequence indices\n","            self.rng.shuffle(sequence_indices)\n","\n","            # Compute the number of batches\n","            num_batches = np.ceil(len(sequence_indices) / self.batch_size)\n","\n","            # Loop over all possible batches of given length and add to list of all batches\n","            all_batches += [batch_indices for batch_indices in np.array_split(sequence_indices, num_batches)]\n","\n","        # Shuffle list of all batches; this shuffles the order of batches but keeps their internal structure the same\n","        self.rng.shuffle(all_batches)\n","        for batch in all_batches:\n","          yield(np.asarray(batch))\n","\n","\n","    def show_batches(self):\n","      '''\n","      Print the different possible word lengths, the number of samples with each word length,\n","      the number of batches of size self.batch_size that can be made out of those samples,\n","      and the remainder, i.e. the number of samples in the final, smallest batch.\n","      (Note: if remainder is 0, that means the number of samples falls perfectly in n batches.)\n","      '''\n","      print(f'Length    # Samples    # Batches    Avg Batch Size')\n","      for length in self.unique_lengths:\n","          num_samples = len(self.samples[length])\n","          num_batches = np.ceil(num_samples / self.batch_size)\n","          average = num_samples / num_batches\n","          print(f'{length:>6} {num_samples:>12} {num_batches:>12.0f} {average:>12.1f}')\n","\n","    def dropped_samples(self):\n","      '''\n","      Return dictionary of all words dropped from dataset for having too few samples of that length.\n","      '''\n","      small_samples = {}\n","      for length in self.small_samples:\n","        small_samples[length] = self.samples[length]\n","      return small_samples\n","\n","    def show_dropped_samples(self):\n","      '''\n","      Print the word lengths that were dropped from the dataset, and the total number of words of each length.\n","      '''\n","      dropped_samples = self.dropped_samples()\n","      print('Dropped Samples \\n')\n","      print('Length    # Samples')\n","      for key, value in dropped_samples.items():\n","        print(f'{key:>6} {len(value):>12}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BDtU56jEnvTP"},"outputs":[],"source":["train_sampler = EqualLengthsBatchSampler(train_ds, batch_size, seed)\n","val_sampler = EqualLengthsBatchSampler(val_ds, batch_size, seed)\n","uniform_train_sampler = EqualLengthsBatchSampler(uniform_train_ds, batch_size, seed)\n","uniform_val_sampler = EqualLengthsBatchSampler(uniform_val_ds, batch_size, seed)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":209,"status":"ok","timestamp":1712979054655,"user":{"displayName":"Will L","userId":"12700959880195069981"},"user_tz":300},"id":"tcSE9xU8_A5e","outputId":"49d5da88-66fa-41b6-b128-c6716f715819"},"outputs":[{"output_type":"stream","name":"stdout","text":["Length    # Samples    # Batches    Avg Batch Size\n","     1           72            2         36.0\n","     2         1268           20         63.4\n","     3         8924          140         63.7\n","     4        23710          371         63.9\n","     5        44038          689         63.9\n","     6        59124          924         64.0\n","     7        71245         1114         64.0\n","     8        75507         1180         64.0\n","     9        65352         1022         63.9\n","    10        50168          784         64.0\n","    11        34973          547         63.9\n","    12        24382          381         64.0\n","    13        15996          250         64.0\n","    14        10412          163         63.9\n","    15         6930          109         63.6\n","    16         4409           69         63.9\n","    17         2812           44         63.9\n","    18         1651           26         63.5\n","    19          972           16         60.8\n","    20          488            8         61.0\n","    21          291            5         58.2\n","    22          136            3         45.3\n","    23           75            2         37.5\n"]}],"source":["train_sampler.show_batches()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":185,"status":"ok","timestamp":1712979099817,"user":{"displayName":"Will L","userId":"12700959880195069981"},"user_tz":300},"id":"Ua6O8erIBMUz","outputId":"bd4cfe48-2ebf-4cdf-98a1-e32282144465"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dropped Samples \n","\n","Length    # Samples\n","    24           29\n","    25           19\n","    26            6\n","    27            4\n","    31            1\n"]}],"source":["train_sampler.show_dropped_samples()"]},{"cell_type":"code","source":["uniform_train_sampler.show_batches()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jgt1zhB3gwDl","executionInfo":{"status":"ok","timestamp":1712979126487,"user_tz":300,"elapsed":178,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"a55ea902-65d3-4e26-b18e-fc3baaad4686"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length    # Samples    # Batches    Avg Batch Size\n","     2          386            7         55.1\n","     3         2890           46         62.8\n","     4         7774          122         63.7\n","     5        14917          234         63.7\n","     6        18638          292         63.8\n","     7        21184          331         64.0\n","     8        21619          338         64.0\n","     9        18055          283         63.8\n","    10        13649          214         63.8\n","    11         9308          146         63.8\n","    12         6137           96         63.9\n","    13         3632           57         63.7\n","    14         2292           36         63.7\n","    15         1417           23         61.6\n","    16          894           14         63.9\n","    17          530            9         58.9\n","    18          293            5         58.6\n","    19          199            4         49.8\n","    20           77            2         38.5\n","    21           48            1         48.0\n"]}]},{"cell_type":"code","source":["uniform_train_sampler.show_dropped_samples()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xc5uNwrThF9z","executionInfo":{"status":"ok","timestamp":1712979224825,"user_tz":300,"elapsed":163,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"9c7a4862-4d9d-4739-ee46-7954076d62b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dropped Samples \n","\n","Length    # Samples\n","     1           20\n","    22           20\n","    23           10\n","    24            4\n","    25            4\n","    27            3\n"]}]},{"cell_type":"code","source":["train_sampler = EqualLengthsBatchSampler(train_ds, batch_size, seed)\n","val_sampler = EqualLengthsBatchSampler(val_ds, batch_size, seed)"],"metadata":{"id":"To7GSAjfi0zW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gSjhSYyF6rTR"},"outputs":[],"source":["train_dl = DataLoader(train_ds, batch_sampler=train_sampler)\n","val_dl = DataLoader(val_ds, batch_sampler=val_sampler)\n","test_dl = DataLoader(test_ds, batch_size=1, shuffle=False)"]},{"cell_type":"code","source":["val_sampler = EqualLengthsBatchSampler(val_ds, batch_size, seed=None)\n","val_dl = DataLoader(val_ds, batch_sampler=val_sampler)\n","for epoch in range(3):\n","  print(epoch)\n","  for i, batch in enumerate(val_dl):\n","    if i % 100 == 0:\n","      print(batch[3][:10])\n","  print()"],"metadata":{"id":"MlU6yXM-oolu","executionInfo":{"status":"ok","timestamp":1712981221805,"user_tz":300,"elapsed":2679,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"dc0d32eb-b2a0-4b84-f7f6-e7fb92d0661a","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","('Oljebyte', 'b{lIsk3t', 'Dimotici', 't5t{l@tI', 'St&firUN', 'qhqudrnd', 'h6grAvid', 'orlqnemf', 'kaJmakam', 'parasito')\n","('hvjtkd', 'spr5@r', '=&p@ln', 'glfRma', 'bOll4k', 'fOl*m&', ')3s7iT', 'wjarja', 'BftB@n', 'p3rk@t')\n","('fOXkINsInstIt3t', 'dir@tLndirEkt|r', 'pOstseG@lMtomat', 'eGalizatsifOnts', 'kOntraIndikatsi', 'pOstseG@lhAnd@l', 'apUt4kstEknIker', 'xElvf9rgl9melse', 'EktenskApsanb}d', 'v@rniwINsidejal')\n","('kOnUkO', 'p#sw3d', 'krEwso', 'kOyOtE', 'kORTEL', 'rhwleh', 'vudqkd', 'vlffma', 'jok@r@', 'dr5be9')\n","('EnxAbOnAdO', 'qlrudwowjr', 't4tragOnAl', 'xl1xolivje', 'vEkstmetud', 'eksomalino', 'krOsk}ntri', 'fluttuante', 'Opdrag@ls@', 'xUstAmEntE')\n","('eoqhxkd', 'br}dg0m', 'peretti', 'SmEl=@n', 'rAmsvAT', 'aNnblAd', 'g@Sv&=@', 'YpIxkWt', 'santone', 'sepjat3')\n","('wjsle3ek', 'sapunaDa', 'kvElsb9n', 'vormal@x', 'Sl]khAls', 'kled@bun', 'sxElpfIs', 'hoSteSka', 'BsrXx@rn', 'p3g@t@rI')\n","('akupunKt5ra', 'aftoelehxos', 'tOpres0ltAt', '3ventyZfIlm', 'agresIvIt4t', 'n1raz73kov3', 'roSpO9)edlo', 'suxop1rnoST', 'sIf@rskrIft', 'r4gelsYst4m')\n","('qlwkrma', '1dd@kqN', 'riSVf@l', '7f3gkek', 'sinoveH', 'labikos', 'sxOltKt', 'wErkupe', 'skrEd@r', 'leno0iT')\n","('sxOtkAlf', 'rampante', 'sUfRIdOR', 'rywErk@r', 'mElkspKs', 'riSkovaT', 'jOdsprit', 'BeS)iIka', 'x@laG@rt', 'regn@rIS')\n","\n","1\n","('tidnINsprEs', 'anfzmfjwlek', 'zwEmbAtErAs', 'vWt@rfErkBf', 'mOntaZ@foto', 'xERmInATIOn', 'epitropikos', 'possibilita', 'molprUtUkOl', 'fliz@nleg@r')\n","('lUN@vev', 'romadza', 'fnOskIg', 'smop3sI', 'LtstEl@', 'x}mirIN', 'x@vKnst', '5xogkek', 'Afsmek@', 'Resesif')\n","('SEtl@nd', 'nylagIN', 'AvsElja', 'rElAtiv', 'grEsl4k', 'lEbAntE', 'Dracena', 'kjulQts', 'alberik', 'lupenka')\n","('zoo', 'oma', 'oG@', 'kok', 'sud', 'dIl', 'lox', 'bol', 'kra', 'iri')\n","('rlEhdckek', 'tAtuwerIN', 'Sta=dinst', 'myrb@sxOt', 'lambretta', 'brUd4rbuk', 'inytilize', 'afruritos', 'pOstopn@r', 'spKt@xhKt')\n","('BfklBb@n', 'melkev@r', 'vlfkalem', 'kONl@bit', 'l}xtklEp', 'gokatore', 'pIfIgh4t', 'nAt]rtr]', 'vithorIg', 'novarese')\n","('Kd1K', '4lak', 'tEnA', 'aRSe', '{r@s', 'Olaz', 'fris', 'grip', 'ydan', 'bubu')\n","('valEnsiG@tAl', 'dEtERmInAntE', 'r@GerINsfOrm', '9penjETIgh4t', 'akalierjitos', 'teknUkrAtIsk', 'gmflanfogkek', 'ineccepibile', 'sAmsvaXb6nIN', 'pnevmatistis')\n","('dAgbrOt', 'r0msd9r', '5pRim9R', 'S3rblOs', 'bludbuk', 'kARtILA', 'b@vlEk@', 'sypErb@', 'vikINIS', 'ruslsck')\n","('bUks@lUm@', 'nYmfUmani', 'hOb@lsxLt', 'UMamentik', 'v@rhArdIN', 'Ots@let@r', 'p$nbr5k@R', 'ostedssak', 'tjutIl@rI', 'slKkmOs@l')\n","\n","2\n","('jevma', 'haLaJ', 'iltOn', 'S)l@n', 'sQl@s', 'EnjEm', 'magna', 'mVk@l', 'mitik', 'volym')\n","('delegat', 'sLk@r@x', 'wlqkdtl', 'mAN@orI', 'kontini', 'arenile', 'kErndXJ', 'bwlydtn', 'sEnJUrI', 'bleknEb')\n","('bIzdIk', 'larini', 's2dkIk', 'rIt2@R', 'miL1d2', 'fjElIg', 'rEmban', 'makyle', 'arkuri', 'mixani')\n","('vIsth}s', 'spurh3n', 'taRtine', 'hIpst@R', 'fyR*taZ', 'hAlUgen', 'bl#stQf', 'titylER', 'bAkst2t', 'sOfRItO')\n","('solimato', 'vaskania', 'm{dwUm@n', 'mIsx@wat', 'snObIsm@', 'rljdskek', 'S}deLina', 'skAlk@t@', 'SYrkUjuD', 'torfl2de')\n","('dese)ihal28', 'cibernEtika', 'lEt@rzEt@rK', 'zUp@nk&sp@r', 'oT9krab1vaT', 'nErvsEntr0m', 'Inf}xunsj}r', 'siStematika', 'tel@foNket@', '&rbitr&=ion')\n","('glaWnf', 'podr3T', 'zilsik', 'thswlf', '{r@b@l', 'g@=Er@', 'velArm', 'kw1k@R', 'clstjs', 'tOksin')\n","('bRILAntE', 'ErprobUN', 'aksestos', 'francine', 'rozm39ka', 'pAvIljun', 'komynote', 'lev@nd@x', 'Ins2vnIN', 'dopoD3ST')\n","('katalojizo', 'alisiDotos', 'sInjalkl|r', 'm4djElpare', 'UravlednIN', 'mazzarElli', 'ORganistik', 'vWt@rk/n@n', 'tonelAxt@x', 'xeneralIst')\n","('cinkwale', 'bOnfrys@', 'br9stnIN', 'vWd@nbBm', '&pklIN@n', 'sn2s9rja', 'wotngkek', 'xkagjark', 's0balt3M', 'Alwet@nt')\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1712884908865,"user":{"displayName":"Will L","userId":"12700959880195069981"},"user_tz":300},"id":"ZkmGLmEABsof","outputId":"995b2dd9-3e9c-40b9-caca-8750c0f18db1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Batch Size: 64\n","Train Samples: 502994    Val Samples: 62874   Test Samples: 62874 \n","Train Batches: 7870      Val Batches: 991     Test Batches: 62874 \n"]}],"source":["print(f'Batch Size: {batch_size}')\n","print(f'Train Samples: {len(train_ds):<8}  Val Samples: {len(val_ds):<6}  Test Samples: {len(test_ds):<6}')\n","print(f'Train Batches: {len(train_dl):<8}  Val Batches: {len(val_dl):<6}  Test Batches: {len(test_dl):<6}')"]},{"cell_type":"code","source":["for lang in languages:\n","  print(lang[1])\n","  with open(os.path.join(data_folder, 'Original', 'LOO', f'LOO_{lang[1]}_Train_Original.pickle'), 'rb') as f:\n","    loo_train_ds = pickle.load(f)\n","  loo_train_sampler = EqualLengthsBatchSampler(loo_train_ds, batch_size, seed)\n","  loo_train_sampler.show_dropped_samples()\n","  drops = loo_train_sampler.dropped_samples()\n","  print('Total:', sum([len(val) for val in drops.values()]))\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vF9qLm7EZ_mZ","executionInfo":{"status":"ok","timestamp":1718248118334,"user_tz":300,"elapsed":60298,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"e992e081-4d4e-47e0-a715-f4034112ad81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Czech\n","Dropped Samples \n","\n","Length    # Samples\n","    25           19\n","    26            5\n","    27            4\n","    31            1\n","Total: 29\n","\n","Dutch\n","Dropped Samples \n","\n","Length    # Samples\n","    23           25\n","    24           13\n","    25            5\n","    26            2\n","    27            1\n","Total: 46\n","\n","English\n","Dropped Samples \n","\n","Length    # Samples\n","    25           19\n","    26            6\n","    27            3\n","    31            1\n","Total: 29\n","\n","French\n","Dropped Samples \n","\n","Length    # Samples\n","    25           19\n","    26            6\n","    27            3\n","    31            1\n","Total: 29\n","\n","German\n","Dropped Samples \n","\n","Length    # Samples\n","    24           31\n","    25           15\n","    26            6\n","    27            3\n","    31            1\n","Total: 56\n","\n","Greek\n","Dropped Samples \n","\n","Length    # Samples\n","    25           19\n","    26            6\n","    27            4\n","    31            1\n","Total: 30\n","\n","Italian\n","Dropped Samples \n","\n","Length    # Samples\n","    25           19\n","    26            4\n","    27            3\n","    31            1\n","Total: 27\n","\n","Korean\n","Dropped Samples \n","\n","Length    # Samples\n","    25           19\n","    26            6\n","    27            4\n","    31            1\n","Total: 30\n","\n","Norwegian\n","Dropped Samples \n","\n","Length    # Samples\n","    24           31\n","    25           19\n","    26            6\n","    27            4\n","    31            1\n","Total: 61\n","\n","Spanish\n","Dropped Samples \n","\n","Length    # Samples\n","    25           18\n","    26            6\n","    27            4\n","    31            1\n","Total: 29\n","\n","Swedish\n","Dropped Samples \n","\n","Length    # Samples\n","    24           27\n","    25           16\n","    26            6\n","    27            4\n","    31            1\n","Total: 54\n","\n","Turkish\n","Dropped Samples \n","\n","Length    # Samples\n","    24           31\n","    25           17\n","    26            6\n","    27            4\n","    31            1\n","Total: 59\n","\n"]}]},{"cell_type":"code","source":["for lang in languages:\n","  print(lang[1])\n","  with open(os.path.join(data_folder, 'Original', 'LOO', f'LOO_{lang[1]}_Val_Original.pickle'), 'rb') as f:\n","    loo_val_ds = pickle.load(f)\n","  loo_val_sampler = EqualLengthsBatchSampler(loo_val_ds, batch_size, seed)\n","  loo_val_sampler.show_dropped_samples()\n","  drops = loo_val_sampler.dropped_samples()\n","  print('Total:', sum([len(val) for val in drops.values()]))\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mCwgTKRTkgSa","executionInfo":{"status":"ok","timestamp":1718248174408,"user_tz":300,"elapsed":8028,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"ceb03100-fdf6-48da-a6dc-77e09758e1ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Czech\n","Dropped Samples \n","\n","Length    # Samples\n","     1            6\n","    18           27\n","    19           19\n","    20            9\n","    21            6\n","    22            1\n","    24            1\n","Total: 69\n","\n","Dutch\n","Dropped Samples \n","\n","Length    # Samples\n","     1           10\n","    24           21\n","    25           14\n","    26            4\n","    27            3\n","    31            1\n","Total: 53\n","\n","English\n","Dropped Samples \n","\n","Length    # Samples\n","     1            8\n","    18            3\n","    19            4\n","    17           15\n","Total: 30\n","\n","French\n","Dropped Samples \n","\n","Length    # Samples\n","     1           12\n","    17           17\n","    18            7\n","    19            3\n","    21            1\n","Total: 40\n","\n","German\n","Dropped Samples \n","\n","Length    # Samples\n","     1           10\n","    20           23\n","    21           19\n","    22            7\n","    23            1\n","    24            1\n","    25            2\n","    27            1\n","Total: 64\n","\n","Greek\n","Dropped Samples \n","\n","Length    # Samples\n","     1            3\n","    18           25\n","    19           15\n","    20            6\n","    21            2\n","Total: 51\n","\n","Italian\n","Dropped Samples \n","\n","Length    # Samples\n","     1            4\n","    20           16\n","    21            9\n","    22            6\n","    23            1\n","    24            1\n","    26            2\n","Total: 39\n","\n","Korean\n","Dropped Samples \n","\n","Length    # Samples\n","     1           15\n","    17            9\n","    18            3\n","    19            2\n","    20            1\n","    21            1\n","    22            1\n","Total: 32\n","\n","Norwegian\n","Dropped Samples \n","\n","Length    # Samples\n","     1            9\n","    21           20\n","    22           14\n","    23            4\n","    24            3\n","Total: 50\n","\n","Spanish\n","Dropped Samples \n","\n","Length    # Samples\n","     2            9\n","    14           20\n","    15           13\n","Total: 42\n","\n","Swedish\n","Dropped Samples \n","\n","Length    # Samples\n","    24            7\n","     1            2\n","    25            3\n","    23           19\n","Total: 31\n","\n","Turkish\n","Dropped Samples \n","\n","Length    # Samples\n","     1            2\n","    14           23\n","    15           10\n","    16            6\n","    17            2\n","    18            2\n","Total: 45\n","\n"]}]},{"cell_type":"code","source":["batches = dict()\n","loo_train_sampler = EqualLengthsBatchSampler(loo_train_ds, batch_size, seed)\n","loo_train_dl = DataLoader(loo_train_ds, batch_sampler=loo_train_sampler)\n","for i in range(1,32):\n","  batches[i] = {'# Samples':0, '# Batches':0, 'Avg Batch Size':[]}\n","for batch in loo_train_dl:\n","  length = len(batch[0][0])\n","  batches[length]['# Samples'] += len(batch[0])\n","  batches[length]['# Batches'] += 1\n","  batches[length]['Avg Batch Size'] += [len(batch[0])]\n","\n","for length in range(1,32):\n","  if batches[length]['# Samples'] == 0:\n","    del batches[length]\n","  else:\n","    size = batches[length]['Avg Batch Size']\n","    batches[length]['Avg Batch Size'] = sum(size) / len(size)"],"metadata":{"id":"paI1AwgZaH3j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(lang[1])\n","print(f'Length    # Samples    # Batches    Avg Batch Size')\n","for length in batches:\n","    print(f\"{length:>6} {batches[length]['# Samples']:>12} {batches[length]['# Batches']:>12.0f} {batches[length]['Avg Batch Size']:>12.1f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GurClQancpad","executionInfo":{"status":"ok","timestamp":1718248719293,"user_tz":300,"elapsed":224,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"c6d5a9a6-88f8-433d-ae36-06df97536b39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Turkish\n","Length    # Samples    # Batches    Avg Batch Size\n","     1           71            2         35.5\n","     2         1251           20         62.5\n","     3         8618          135         63.8\n","     4        22989          360         63.9\n","     5        42226          660         64.0\n","     6        58253          911         63.9\n","     7        71046         1111         63.9\n","     8        75661         1183         64.0\n","     9        66163         1034         64.0\n","    10        50936          796         64.0\n","    11        35714          559         63.9\n","    12        24983          391         63.9\n","    13        16311          255         64.0\n","    14        10622          166         64.0\n","    15         7025          110         63.9\n","    16         4468           70         63.8\n","    17         2887           46         62.8\n","    18         1697           27         62.9\n","    19          982           16         61.4\n","    20          518            9         57.6\n","    21          297            5         59.4\n","    22          141            3         47.0\n","    23           76            2         38.0\n"]}]},{"cell_type":"code","source":["print(lang[1])\n","loo_train_sampler = EqualLengthsBatchSampler(loo_train_ds, batch_size, seed)\n","loo_train_sampler.show_batches()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s03O3hHweRjh","executionInfo":{"status":"ok","timestamp":1718248566788,"user_tz":300,"elapsed":442,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"74424435-30fd-46dc-b4e3-f2b5be6ca517"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Turkish\n","Length    # Samples    # Batches    Avg Batch Size\n","     1           71            2         35.5\n","     2         1251           20         62.5\n","     3         8618          135         63.8\n","     4        22989          360         63.9\n","     5        42226          660         64.0\n","     6        58253          911         63.9\n","     7        71046         1111         63.9\n","     8        75661         1183         64.0\n","     9        66163         1034         64.0\n","    10        50936          796         64.0\n","    11        35714          559         63.9\n","    12        24983          391         63.9\n","    13        16311          255         64.0\n","    14        10622          166         64.0\n","    15         7025          110         63.9\n","    16         4468           70         63.8\n","    17         2887           46         62.8\n","    18         1697           27         62.9\n","    19          982           16         61.4\n","    20          518            9         57.6\n","    21          297            5         59.4\n","    22          141            3         47.0\n","    23           76            2         38.0\n"]}]},{"cell_type":"code","source":["total = 0\n","for length in batches:\n","  total += batches[length]['# Samples']\n","print(lang[1])\n","total"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wUGpdbLSezRw","executionInfo":{"status":"ok","timestamp":1718248741509,"user_tz":300,"elapsed":469,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"585ba551-c7e6-438f-bccd-f5b6cdf98dea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Turkish\n"]},{"output_type":"execute_result","data":{"text/plain":["502935"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["for family in families:\n","  for lang in family[1]:\n","    print(lang[1])\n","    with open(os.path.join(data_folder, 'Original', 'Family', f'{family[0]}_{lang[1]}_Train_Original.pickle'), 'rb') as f:\n","      family_train_ds = pickle.load(f)\n","    family_train_sampler = EqualLengthsBatchSampler(family_train_ds, batch_size, seed)\n","    family_train_sampler.show_dropped_samples()\n","    drops = family_train_sampler.dropped_samples()\n","    print('Total:', sum([len(val) for val in drops.values()]))\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fW7_dIEjmyo9","executionInfo":{"status":"ok","timestamp":1718248876938,"user_tz":300,"elapsed":8354,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"38c93b38-b4b3-43aa-8874-21b05ca10274"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dutch\n","Dropped Samples \n","\n","Length    # Samples\n","     1           18\n","    20           23\n","    21           19\n","    22            7\n","    23            1\n","    24            1\n","    25            2\n","    27            1\n","Total: 72\n","\n","English\n","Dropped Samples \n","\n","Length    # Samples\n","     1           20\n","    24           22\n","    25           16\n","    26            4\n","    27            4\n","    31            1\n","Total: 67\n","\n","German\n","Dropped Samples \n","\n","Length    # Samples\n","     1           18\n","    24           21\n","    25           14\n","    26            4\n","    27            3\n","    31            1\n","Total: 61\n","\n","French\n","Dropped Samples \n","\n","Length    # Samples\n","     1            4\n","    20           16\n","    21            9\n","    22            6\n","    23            1\n","    24            1\n","    26            2\n","Total: 39\n","\n","Italian\n","Dropped Samples \n","\n","Length    # Samples\n","     1           12\n","    17           17\n","    18            7\n","    19            3\n","    21            1\n","Total: 40\n","\n","Spanish\n","Dropped Samples \n","\n","Length    # Samples\n","     1           16\n","    20           16\n","    21           10\n","    22            6\n","    23            1\n","    24            1\n","    26            2\n","Total: 52\n","\n","Norwegian\n","Dropped Samples \n","\n","Length    # Samples\n","    24            7\n","     1            2\n","    25            3\n","    23           19\n","Total: 31\n","\n","Swedish\n","Dropped Samples \n","\n","Length    # Samples\n","     1            9\n","    21           20\n","    22           14\n","    23            4\n","    24            3\n","Total: 50\n","\n"]}]},{"cell_type":"code","source":["for family in families:\n","  for lang in family[1]:\n","    print(lang[1])\n","    with open(os.path.join(data_folder, 'Original', 'Family', f'{family[0]}_{lang[1]}_Val_Original.pickle'), 'rb') as f:\n","      family_val_ds = pickle.load(f)\n","    family_val_sampler = EqualLengthsBatchSampler(family_val_ds, batch_size, seed)\n","    family_val_sampler.show_dropped_samples()\n","    drops = family_val_sampler.dropped_samples()\n","    print('Total:', sum([len(val) for val in drops.values()]))\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zdW7tv-Hnco0","executionInfo":{"status":"ok","timestamp":1718248941038,"user_tz":300,"elapsed":6179,"user":{"displayName":"Will L","userId":"12700959880195069981"}},"outputId":"9f9891d1-7ebd-4bf7-988b-2f775dc165b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dutch\n","Dropped Samples \n","\n","Length    # Samples\n","     1           10\n","    24           21\n","    25           14\n","    26            4\n","    27            3\n","    31            1\n","Total: 53\n","\n","English\n","Dropped Samples \n","\n","Length    # Samples\n","     1            8\n","    18            3\n","    19            4\n","    17           15\n","Total: 30\n","\n","German\n","Dropped Samples \n","\n","Length    # Samples\n","     1           10\n","    20           23\n","    21           19\n","    22            7\n","    23            1\n","    24            1\n","    25            2\n","    27            1\n","Total: 64\n","\n","French\n","Dropped Samples \n","\n","Length    # Samples\n","     1           12\n","    17           17\n","    18            7\n","    19            3\n","    21            1\n","Total: 40\n","\n","Italian\n","Dropped Samples \n","\n","Length    # Samples\n","     1            4\n","    20           16\n","    21            9\n","    22            6\n","    23            1\n","    24            1\n","    26            2\n","Total: 39\n","\n","Spanish\n","Dropped Samples \n","\n","Length    # Samples\n","     2            9\n","    14           20\n","    15           13\n","Total: 42\n","\n","Norwegian\n","Dropped Samples \n","\n","Length    # Samples\n","     1            9\n","    21           20\n","    22           14\n","    23            4\n","    24            3\n","Total: 50\n","\n","Swedish\n","Dropped Samples \n","\n","Length    # Samples\n","    24            7\n","     1            2\n","    25            3\n","    23           19\n","Total: 31\n","\n"]}]}],"metadata":{"colab":{"collapsed_sections":["sRl3jE7Ktm6U","XDcuRU4SEEY8","DHt_e7S6KY_o"],"provenance":[{"file_id":"1JIhkHg1ZYYLmn1HEO44plhbBsPPOorgG","timestamp":1712946518464},{"file_id":"1KMHKGadpyk8zkjHCyto7w3LtX1I8hvhl","timestamp":1705019942522},{"file_id":"1hhd3TkzIXHJ1McwMIvOZOw1oY43nxUJd","timestamp":1703746822248},{"file_id":"1x79qokdqQgWR_n-VrW5E35ei7dlRbA3G","timestamp":1700235505048}],"toc_visible":true,"authorship_tag":"ABX9TyOaF1pS+45L9YQ9S9nGx0gZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}